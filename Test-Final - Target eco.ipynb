{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36dbd8c",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba059a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "#load datasets\n",
    "\n",
    "airbnb_crime = pd.read_csv(r'C:\\Madhuri\\projects\\ML_project\\Test_ML\\cleaned_airbnb_crime - Final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca2eac8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                  int64\n",
       "last_review                                        object\n",
       "reviews_per_month                                 float64\n",
       "calculated_host_listings_count                      int64\n",
       "availability_365                                    int64\n",
       "neighbourhood_group_cleansed                       object\n",
       "neighbourhood_cleansed                             object\n",
       "latitude                                          float64\n",
       "longitude                                         float64\n",
       "price                                             float64\n",
       "minimum_nights                                      int64\n",
       "number_of_reviews                                   int64\n",
       "room_type                                          object\n",
       "bedrooms                                          float64\n",
       "bathrooms                                         float64\n",
       "beds                                              float64\n",
       "review_scores_rating                              float64\n",
       "review_scores_accuracy                            float64\n",
       "review_scores_cleanliness                         float64\n",
       "review_scores_checkin                             float64\n",
       "review_scores_communication                       float64\n",
       "review_scores_location                            float64\n",
       "review_scores_value                               float64\n",
       "crime_count                                         int64\n",
       "distance_to_statue_of_liberty                     float64\n",
       "distance_to_times_square                          float64\n",
       "distance_to_central_park                          float64\n",
       "distance_to_empire_state_building                 float64\n",
       "distance_to_brooklyn_bridge                       float64\n",
       "distance_to_rockefeller_center                    float64\n",
       "distance_to_one_world_trade_center                float64\n",
       "distance_to_broadway                              float64\n",
       "distance_to_grand_central_terminal                float64\n",
       "distance_to_the_metropolitan_museum_of_art        float64\n",
       "distance_to_american_museum_of_natural_history    float64\n",
       "distance_to_9/11_memorial_and_museum              float64\n",
       "distance_to_fifth_avenue                          float64\n",
       "distance_to_chrysler_building                     float64\n",
       "distance_to_the_high_line                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_crime.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0fee4",
   "metadata": {},
   "source": [
    "Spling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36e9c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = airbnb_crime.select_dtypes(include=[np.number]).drop(columns=['price'])\n",
    "y = airbnb_crime['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711874da",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bcb0757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regressor Performance:\n",
      "R²: -0.0267\n",
      "MAE: 79.6019\n",
      "MSE: 26753.8188\n",
      "RMSE: 163.5659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=10) # n_neighbours is a \"hyperparameter\", which can be changed to improve performance of the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('K-Nearest Neighbors Regressor Performance:')\n",
    "print(f'R²: {r2:.4f}')\n",
    "print(f'MAE: {mae:.4f}')    \n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02370b",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b20b4803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Performance:\n",
      "R²: 0.3334\n",
      "MAE: 57.9722\n",
      "MSE: 17370.8100\n",
      "RMSE: 131.7984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "\n",
    "\n",
    "print('\\nLinear Regression Performance:')\n",
    "print(f'R²: {r2_lr:.4f}')\n",
    "print(f'MAE: {mae_lr:.4f}')\n",
    "print(f'MSE: {mse_lr:.4f}')\n",
    "print(f'RMSE: {rmse_lr:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "246a1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dc63e",
   "metadata": {},
   "source": [
    "Spliting by selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09932ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = airbnb_crime[['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'availability_365', 'crime_count',\n",
    "               'calculated_host_listings_count', 'distance_to_statue_of_liberty', 'distance_to_times_square', 'neighbourhood_group_cleansed', 'room_type','bathrooms', 'bedrooms','reviews_per_month', 'review_scores_accuracy',\n",
    "               'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "               'review_scores_location', 'review_scores_value']]\n",
    "y = airbnb_crime['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c636834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bd2e1",
   "metadata": {},
   "source": [
    "Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85bb8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_features = ['latitude', 'longitude', 'minimum_nights', \n",
    "                    'number_of_reviews', 'availability_365', 'crime_count',\n",
    "                    'calculated_host_listings_count', \n",
    "                    'distance_to_statue_of_liberty', 'distance_to_times_square','bathrooms', 'bedrooms','reviews_per_month', 'review_scores_accuracy',\n",
    "               'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "               'review_scores_location', 'review_scores_value']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[numeric_features])\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Replace numeric columns with scaled versions\n",
    "X_train_scaled[numeric_features] = scaler.transform(X_train[numeric_features])\n",
    "X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b953122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put transformed data into a DataFrame (only numeric features)\n",
    "X_train_transformed = pd.DataFrame(scaler.transform(X_train[numeric_features]), columns=numeric_features, index=X_train.index)\n",
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test[numeric_features]), columns=numeric_features, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa239db",
   "metadata": {},
   "source": [
    "Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62040e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Target encoding function with smoothing\n",
    "def target_encode(train_series, target_series, smoothing=10):\n",
    "    \"\"\"\n",
    "    train_series: categorical column from training data\n",
    "    target_series: target column from training data (e.g., price)\n",
    "    smoothing: higher value -> more smoothing towards global mean\n",
    "    \"\"\"\n",
    "    global_mean = target_series.mean()\n",
    "    \n",
    "    # Aggregate mean and count per category\n",
    "    agg = train_series.to_frame().join(target_series).groupby(train_series.name)['price'].agg(['mean','count'])\n",
    "    \n",
    "    # Smoothed mean\n",
    "    smooth = (agg['count'] * agg['mean'] + smoothing * global_mean) / (agg['count'] + smoothing)\n",
    "    \n",
    "    # Map the original column to its smoothed mean\n",
    "    return train_series.map(smooth), smooth, global_mean\n",
    "\n",
    "# Apply target encoding to training data\n",
    "train_encoded, encoding_map, global_mean = target_encode(\n",
    "    airbnb_crime.loc[X_train.index, 'neighbourhood_group_cleansed'],\n",
    "    airbnb_crime.loc[X_train.index, 'price'],\n",
    "    smoothing=10\n",
    ")\n",
    "\n",
    "# Add encoded column to your training features\n",
    "X_train_encoded = X_train_transformed.copy()\n",
    "X_train_encoded['neighbourhood_group_cleansed_enc'] = train_encoded\n",
    "\n",
    "# Apply the encoding to test data\n",
    "test_encoded = airbnb_crime.loc[X_test.index, 'neighbourhood_group_cleansed'].map(encoding_map).fillna(global_mean)\n",
    "X_test_encoded = X_test_transformed.copy()\n",
    "X_test_encoded['neighbourhood_group_cleansed_enc'] = test_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcbca0",
   "metadata": {},
   "source": [
    "Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69051d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naveen\\AppData\\Local\\Temp\\ipykernel_15076\\3696907422.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train_label = X_train[['room_type']].replace(room_type_map)\n",
      "C:\\Users\\Naveen\\AppData\\Local\\Temp\\ipykernel_15076\\3696907422.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_label = X_test[['room_type']].replace(room_type_map)\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping\n",
    "room_type_map = {\n",
    "    'Entire home/apt': 4,\n",
    "    'Hotel room': 3,\n",
    "    'Private room': 2,\n",
    "    'Shared room': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to training and test sets\n",
    "X_train_label = X_train[['room_type']].replace(room_type_map)\n",
    "X_test_label = X_test[['room_type']].replace(room_type_map)\n",
    "\n",
    "# Combine with your other encoded features\n",
    "\n",
    "X_train_t = pd.concat(\n",
    "    [X_train_encoded.reset_index(drop=True),\n",
    "     X_train_label.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_test_t = pd.concat(\n",
    "    [X_test_encoded.reset_index(drop=True),\n",
    "     X_test_label.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cb609",
   "metadata": {},
   "source": [
    "Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "247f9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression Performance:\n",
      "\n",
      "--- Train Set ---\n",
      "R2 score: 0.1803\n",
      "Mean Squared Error: 34021.1548\n",
      "Mean Absolute Error: 48.0629\n",
      "Root Mean Squared Error: 184.4482\n",
      "\n",
      "--- Test Set ---\n",
      "R2 score: 0.3447\n",
      "Mean Squared Error: 17075.8640\n",
      "Mean Absolute Error: 47.8511\n",
      "Root Mean Squared Error: 130.6746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=160)\n",
    "knn.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = knn.predict(X_train_t)\n",
    "y_test_pred = knn.predict(X_test_t)\n",
    "\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"KNN Regression Performance:\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R2 score: {train_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {train_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {train_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {train_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R2 score: {test_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {test_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37814cfe",
   "metadata": {},
   "source": [
    "Obs: test performance is better than train. Underfitting (Train r2 = 0,18 < Test r2 = 0.34). Results still modest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f94d8b",
   "metadata": {},
   "source": [
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e3a5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "\n",
      "--- Train Set ---\n",
      "R2 score: 0.1680\n",
      "Mean Squared Error: 34532.9907\n",
      "Mean Absolute Error: 54.3950\n",
      "Root Mean Squared Error: 185.8305\n",
      "\n",
      "--- Test Set ---\n",
      "R2 score: 0.3570\n",
      "Mean Squared Error: 16756.6050\n",
      "Mean Absolute Error: 53.3023\n",
      "Root Mean Squared Error: 129.4473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = lr.predict(X_train_t)\n",
    "y_test_pred = lr.predict(X_test_t)\n",
    "\n",
    "#Train\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Test\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Linear Regression Performance:\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R2 score: {train_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {train_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {train_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {train_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R2 score: {test_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {test_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012ad27",
   "metadata": {},
   "source": [
    "OBS: Underfitting: Linear Regression  low train R² → the models are too simple to fully capture the data patterns. (Train r2 = 0,17 < Test r2 = 0.36)\n",
    "\n",
    "This is unusual but can happen if the train set has outliers or higher variance than the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08748ae1",
   "metadata": {},
   "source": [
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b879d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Performance:\n",
      "\n",
      "--- Train Set ---\n",
      "R2 score: 0.4848\n",
      "Mean Squared Error: 21382.8023\n",
      "Mean Absolute Error: 48.9083\n",
      "Root Mean Squared Error: 146.2286\n",
      "\n",
      "--- Test Set ---\n",
      "R2 score: -0.6160\n",
      "Mean Squared Error: 42111.4212\n",
      "Mean Absolute Error: 54.5766\n",
      "Root Mean Squared Error: 205.2107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(\n",
    "    max_depth=10,       # try tuning this\n",
    "    min_samples_split=2,\n",
    "    max_leaf_nodes=30   # similar to controlling depth\n",
    ")\n",
    "\n",
    "dt_reg.fit(X_train_t, y_train)\n",
    "\n",
    "y_train_pred = dt_reg.predict(X_train_t)\n",
    "y_test_pred = dt_reg.predict(X_test_t)\n",
    "\n",
    "# Train\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Test\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Decision Tree Regression Performance:\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R2 score: {train_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {train_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {train_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {train_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R2 score: {test_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {test_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c73552",
   "metadata": {},
   "source": [
    "Train Set\n",
    "\n",
    "R² = 0.4848 → Your model explains ~48% of the variance in training data.\n",
    "\n",
    "MSE = 21382.8, RMSE = 146.23, MAE = 48.91 → Errors are moderate, but we don’t yet know the scale of your target variable.\n",
    "\n",
    "Test Set\n",
    "\n",
    "R² = -0.5951 → This is very concerning. Negative R² means your model performs worse than a simple baseline (mean prediction).\n",
    "\n",
    "MSE = 41567.02, RMSE = 203.88 → Errors are significantly higher than in training.\n",
    "\n",
    "MAE = 54.33 → Slightly higher than training, but MSE/RMSE increased more, indicating some large errors/outliers in predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdef27",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98a77051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Performance:\n",
      "\n",
      "--- Train Set ---\n",
      "R² Score: 0.7926\n",
      "Mean Squared Error: 8608.6724\n",
      "Mean Absolute Error: 38.1937\n",
      "Root Mean Squared Error: 92.7829\n",
      "\n",
      "--- Test Set ---\n",
      "R² Score: 0.3895\n",
      "Mean Squared Error: 15908.0758\n",
      "Mean Absolute Error: 45.1783\n",
      "Root Mean Squared Error: 126.1272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Model\n",
    "rf_boot = RandomForestRegressor(\n",
    "    n_estimators=50, \n",
    "    max_depth=10, \n",
    "    bootstrap=True, \n",
    "    random_state=42\n",
    ")\n",
    "rf_boot.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = rf_boot.predict(X_train_t)\n",
    "y_test_pred  = rf_boot.predict(X_test_t)\n",
    "\n",
    "# Train\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "# Test\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regression Performance:\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R² Score: {train_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {train_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {train_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {train_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {test_mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336255b",
   "metadata": {},
   "source": [
    "Train Set\n",
    "\n",
    "R² = 0.7907 → The model explains ~79% of the variance in the training data, much better than before.\n",
    "\n",
    "MSE = 8686.36, RMSE = 93.20, MAE = 38.28 → Errors are significantly lower than your first attempt.\n",
    "\n",
    "Test Set\n",
    "\n",
    "R² = 0.3814 → Now the model explains ~38% of the variance in unseen data. This is positive (compared to negative R² before), but there’s still a gap.\n",
    "\n",
    "MSE = 16119.39, RMSE = 126.96, MAE = 45.44 → Test errors are higher than training, but not as dramatically as before.\n",
    "\n",
    "2. Key Insights\n",
    "\n",
    "Overfitting reduced but not eliminated:\n",
    "\n",
    "The drop from 0.79 (train) → 0.38 (test) shows the model still captures training patterns too specifically.\n",
    "\n",
    "Improved generalization:\n",
    "\n",
    "The test set R² went from -0.59 → 0.38, indicating your changes (likely pruning or parameter tuning) helped a lot.\n",
    "\n",
    "Error distribution:\n",
    "\n",
    "MAE and RMSE on test are higher than training, but the gap is reasonable. RMSE > MAE suggests some larger errors still exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192879dc",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a429fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression Performance:\n",
      "\n",
      "--- Train Set ---\n",
      "R² Score: 0.904\n",
      "RMSE: 63.17\n",
      "MAE: 32.10\n",
      "\n",
      "--- Test Set ---\n",
      "R² Score: 0.472\n",
      "RMSE: 117.31\n",
      "MAE: 44.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Define model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_t, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train_t)\n",
    "y_test_pred  = model.predict(X_test_t)\n",
    "\n",
    "# --- Train metrics ---\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_mae  = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2   = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# --- Test metrics ---\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_mae  = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2   = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Results\n",
    "print(\"XGBoost Regression Performance:\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R² Score: {train_r2:.3f}\")\n",
    "print(f\"RMSE: {train_rmse:.2f}\")\n",
    "print(f\"MAE: {train_mae:.2f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R² Score: {test_r2:.3f}\")\n",
    "print(f\"RMSE: {test_rmse:.2f}\")\n",
    "print(f\"MAE: {test_mae:.2f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f153ff",
   "metadata": {},
   "source": [
    "Train Set\n",
    "\n",
    "R² = 0.909 → Excellent fit on training data; the model explains ~91% of the variance.\n",
    "\n",
    "RMSE = 61.44, MAE = 31.84 → Errors are relatively low, indicating very accurate predictions on training data.\n",
    "\n",
    "Test Set\n",
    "\n",
    "R² = 0.462 → The model explains ~46% of the variance in unseen data. This is better than your Decision Tree (0.38) but still not great.\n",
    "\n",
    "RMSE = 118.39, MAE = 44.37 → Test errors are almost double the training errors, suggesting overfitting.\n",
    "\n",
    "2. Key Insights\n",
    "\n",
    "Overfitting is present:\n",
    "\n",
    "Large gap between train R² (0.91) and test R² (0.46) shows the model learned training patterns too specifically.\n",
    "\n",
    "Better than single-tree models:\n",
    "\n",
    "Compared to Decision Tree and your tuned version, XGBoost improves test performance slightly.\n",
    "\n",
    "MAE is similar, but RMSE is higher on test, indicating some large errors (outliers) remain.\n",
    "\n",
    "Potential causes of remaining gap:\n",
    "\n",
    "Data may have noise or outliers.\n",
    "\n",
    "Features may be missing predictive power or require engineering/transformations.\n",
    "\n",
    "Hyperparameters may need tuning to reduce overfitting (e.g., learning rate, max depth, subsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa186b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression with Log-Transformed Target\n",
      "\n",
      "--- Train Set ---\n",
      "R² Score: 0.549\n",
      "RMSE: 136.76\n",
      "MAE: 31.72\n",
      "\n",
      "--- Test Set ---\n",
      "R² Score: 0.568\n",
      "RMSE: 106.08\n",
      "MAE: 38.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_log = np.log1p(airbnb_crime['price'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "l\n",
    "model.fit(X_train_t, y_train)\n",
    "\n",
    "y_train_pred_log = model.predict(X_train_t)\n",
    "y_test_pred_log  = model.predict(X_test_t)\n",
    "\n",
    "y_train_pred = np.expm1(y_train_pred_log)\n",
    "y_test_pred  = np.expm1(y_test_pred_log)\n",
    "y_train_true = np.expm1(y_train)\n",
    "y_test_true  = np.expm1(y_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_true, y_train_pred))\n",
    "train_mae  = mean_absolute_error(y_train_true, y_train_pred)\n",
    "train_r2   = r2_score(y_train_true, y_train_pred)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
    "test_mae  = mean_absolute_error(y_test_true, y_test_pred)\n",
    "test_r2   = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(\"XGBoost Regression with Log-Transformed Target\")\n",
    "\n",
    "print(\"\\n--- Train Set ---\")\n",
    "print(f\"R² Score: {train_r2:.3f}\")\n",
    "print(f\"RMSE: {train_rmse:.2f}\")\n",
    "print(f\"MAE: {train_mae:.2f}\")\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(f\"R² Score: {test_r2:.3f}\")\n",
    "print(f\"RMSE: {test_rmse:.2f}\")\n",
    "print(f\"MAE: {test_mae:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04caf66a",
   "metadata": {},
   "source": [
    "Train Set\n",
    "\n",
    "R² = 0.530 → The model explains ~53% of the variance in the log-transformed target, which is lower than your previous raw-target XGBoost train R² (0.91).\n",
    "\n",
    "RMSE = 139.63, MAE = 31.75 → RMSE increased (because of log transform scale), but MAE stayed low.\n",
    "\n",
    "Test Set\n",
    "\n",
    "R² = 0.565 → Now your test R² is higher than train R², which is unusual but can happen with log transform if the raw target has heavy skew or extreme outliers.\n",
    "\n",
    "RMSE = 106.41, MAE = 38.16 → Test errors are lower than train RMSE (again due to scale differences).\n",
    "\n",
    "2. Key Insights\n",
    "\n",
    "Log transformation helped generalization:\n",
    "\n",
    "Test R² improved from 0.462 → 0.565. That’s a significant boost.\n",
    "\n",
    "Model is less sensitive to extreme high values because log compresses large numbers.\n",
    "\n",
    "Overfitting reduced:\n",
    "\n",
    "Previously, train R² was 0.91 and test R² 0.46 → huge gap.\n",
    "\n",
    "Now train R² = 0.53 and test R² = 0.565 → the model generalizes better, possibly even underfitting slightly.\n",
    "\n",
    "Error interpretation:\n",
    "\n",
    "Because the target is log-transformed, RMSE values are not directly comparable to raw-target RMSE.\n",
    "\n",
    "MAE (in log-space) is often more stable and indicates reasonable prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7a1c4",
   "metadata": {},
   "source": [
    "Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfd65e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.4551969604356766\n",
      "Test R^2: 0.45973952953688546\n",
      "Coefficients: [-0.         -0.         -0.         -0.          0.         -0.\n",
      "  0.         -0.         -0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.00564433  0.28488809]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "print(\"Train R^2:\", lasso.score(X_train_t, y_train))\n",
    "print(\"Test R^2:\", lasso.score(X_test_t, y_test))\n",
    "print(\"Coefficients:\", lasso.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
